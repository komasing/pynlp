{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue\">Praktikum 5. Veeb ja andmestike kogumine</h1>\n",
    "<h3 style=\"color:blue\">Veebiga suhtlemine, <i>crawl</i>'imine ja sotsiaalmeediaga lõbutsemine</h3>\n",
    "<h4>4. oktoober 2016 </h4>\n",
    "<h4>Ülesannete esitamise tähtaeg 18. oktoober.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seni oleme tegelenud tehniliste teemadega, et olla valmis, mil andmed tulevad. Käesolevas praktikumis võtame ohjad enda kätte ning toome andmed enda juurde.\n",
    "\n",
    "Veeb on täis nii staatilisi ohtralt uuritud andmestikke kui ka dünaamilisi pidevalt uuenevaid ja täienevaid. Täna katsume jõudu mõlemaga.\n",
    "\n",
    "Loomuliku keelega töötades on olulisel kohal termin _korpus_, mis tähistab huvipakkuvate dokumentide kogu, mis on sageli lisaks märgendatud keelelise või tähendusliku informatsiooniga. Viimane on eelkõige tõene staatiliste andmestike korral, kuhu pikkade analüüside tulemusel on kantud täiendavat teavet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veebiga suhtlemine\n",
    "\n",
    "_Ülesanne 1. Lugeda (0.5p)_\n",
    "\n",
    "Et saada kasu meie ümber lokkavast andmemerest, on meil tarvis sellega esmalt suhelda. Igapäevaselt saame sellest osa internetilehitseja ehk _brauser_'i vahendusel, külastades uudiseportaale, blogisid ning teisi sotsiaalmeedia lehekülgi. Kui sisestame aadressi brauseri aadressilahtrisse, teeb brauser üldiselt _get_ päringu kindlale ressursile, mille tagajärjel saadetakse harilikult dokument serverist meie arvutisse. Läbi _HTML_ vormide ja _JavaScript_'i koodi on võimalik teha ka _post_, _put_ ja _delete_ päringuid, mis vastutavad vastavalt uute ressursside loomise, loomise ja muutmise ning kustutamise eest. Seega, kui server järgib _HTTP_ standardit, saame _resource17_ eemaldada päringuga\n",
    "\n",
    "    DELETE /resource/resource17.txt HTTP/1.1\n",
    "    Host: www.example.com/\n",
    "    \n",
    "_Post_ ja _put_ katavad tihti sarnast funktsionaalsust, olenevalt serverist.\n",
    "\n",
    "Oluline on mõista, et see, **kuidas _HTTP_ meetodid käituvad ja mida nad teevad, on serveri defineerida**. Seega _get_ ei pruugi alati tagastada mingit ressurssi ning _delete_ midagi kustutada.\n",
    "\n",
    "Veebis surfates ei ole meil tarvis murda pead selle üle, milliseid päringuid milliste argumentidega me tegema peaks, kuivõrd kõik see on veebiarendajate poolt veebilehte sisse ehitatud ning meil jääb üle vaid muretult ringi klõpsata. Kuivõrd meie unistuseks on suur andmestik, siis ei soovi me seda luua aga ükshaaval klõpsides, vaid ihkaksime teha automaagiliselt. Programmaatiliselt peame aga täpselt teadma, milliseid päiseid ja millist informatsiooni peame lisaks kaasa andma, et saada ligipääs unelmate sisule. Oluliseks päiseks on sageli autentimisinformatsioon, et saada ligi mitteavalikele andmetele.\n",
    "\n",
    "_Get_ päringutega on lihtne, sest standardi kohaselt on kogu informatiivne teave serverile talletatud kehas ning seega ressursi pärimine pole oluliselt keerulisem brausimisest. Kui server ootab aga mingi ressursi tagastamiseks _post_ või _put_ päringut, muutub oluliseks nii päringu keha kui ka päised, mida pole alati lihtne päringule veebilehel peale vaadates tuvastada. Sageli peab sellistel juhtudel nägema palju vaeva või paremal juhul tutvuma API dokumentatsiooniga."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmaatiline suhtlus-nuhtlus\n",
    "\n",
    "Püütonis vastutab veebiga suhtlemise eest _urllib.request_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "url = 'http://www.folklore.ee/rl/folkte/myte/kalev/56.html'\n",
    "response = urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Urlopen_ tagastab [_HTTPResponse_ objekti](https://docs.python.org/3/library/http.client.html#httpresponse-objects), mille oluliseimateks meetoditeks on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response.getheaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mille huvipakkuvaim päis on ehk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response.getheader('Content-Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Content-Type_ kirjeldab, millise andmeformaadiga on tegu (ehk kuidas dokumendist teavet eraldada) ning _charset_'i abil vahel ka, millise kodeeringuga on dokument kodeeritud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisaks saab kätte vastuse staatuse, ehk kas päring õnnestus (200), päritud ressursile puudus õigus (401), ressurssi ei leidunud (404), server läks katki päringu peale (500) või muud sellist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kõige oluliseim on aga lehe sisu kätte saada. _Response_'i võime käsitleda mõneti kui _file handler_'it, millest saab lugeda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = urlopen(url).read().decode('utf8') # dekodeerime utf8 abil, kuivõrd kodeeringut pole 'Content-Type' päises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokumendil oli BOM, mis kirjeldas mingit muud kodeeringut. Teeme _smart guess_'i levinud veebi vaikekodeeringu osas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = urlopen(url).read().decode('iso-8859-1')\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lehe sisu analüüsides näeme, et ehkki kodeeringule saime teisel korral pihta, on endiselt omajagu sümboleid veidrad. HTML-is kasutatakse sageli keeruliste sümbolite kuvamiseks HTML _escape_'i. Näiteks _& auml;_ ('a' _umlaut_) on 'ä'. Kui soovime sisu loetavaks teha, peame _unescape_'ima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import html\n",
    "html.unescape(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seni oleme vaadanud aga ainult _get_ päringut. Kui soovime mõnda teist liiki päringut teha - nt _put_'i - läheb kood keerulisemaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "data = b'some added resource content'\n",
    "req = urllib.request.Request(url='http://localhost:8888', data=data,method='PUT')\n",
    "with urllib.request.urlopen(req) as response:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soovime pääseda ligi (_basic_) autentimist nõudvale ressursile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code stolen from https://docs.python.org/3/library/urllib.request.html\n",
    "\n",
    "import urllib.request\n",
    "# Create an OpenerDirector with support for Basic HTTP Authentication...\n",
    "auth_handler = urllib.request.HTTPBasicAuthHandler()\n",
    "auth_handler.add_password(realm='PDQ Application',\n",
    "                          uri='https://mahler:8092/site-updates.py',\n",
    "                          user='klem',\n",
    "                          passwd='kadidd!ehopper')\n",
    "opener = urllib.request.build_opener(auth_handler)\n",
    "# ...and install it globally so it can be used with urlopen.\n",
    "urllib.request.install_opener(opener)\n",
    "urllib.request.urlopen('http://www.example.com/login.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Praktikas on mõistlik kasutada mõnda inimlikuma liidesega teeki.**\n",
    "Väga hea alternatiiv on [Requests: HTTP for Humans](http://docs.python-requests.org/en/master/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Requests_'i _response_ võimaldab kõik vajaliku vastuse kohta kätte saada atribuutide ja meetodite kaudu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Status:',response.status_code)\n",
    "print('Content-Type:',response.headers['content-type'])\n",
    "print('Encoding:',response.encoding)\n",
    "print('Content:',response.text[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faili sisu on juba _unicode_'i dekodeeritud ja kodeering automaatselt tuvastatud. Lisaks on _requests_'iga lihtne teha teist tüüpi päringuid ning mugav autentimine, _cookie_'de, päiste ja ühenduse majandus ning _stream_'imine.\n",
    "\n",
    "Näiteks eelneva _put_'i saame kirjutada järgnevalt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requests.put('http://localhost:8888', data='some data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 2.\n",
    "** Kirjutage funktsioon _retrieve(url,method='get',data=None,headers=None,auth=None)_, millele saaks ette anda ressursi aadressi (_url_), päringu _HTTP_ meetodi (_method_), päringu keha (_data_), päised ning autentimise info ja mis tagastaks ressursi sisu _unicode_ kujul. Lisaprotsessimist pole tarvis teha. (0.5p)**\n",
    "\n",
    "### Boonusülesanne 1.\n",
    "** Kui _retrieve_ kasutab meetodi määramiseks _if-else_ õuduse asemel _requests_ objektilt meetodi pärimist meetodi nime abil, siis lisaks (0.5p). (tutvuda _getattr_ meetodiga ja/või) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requests.__dict__ # üks võimalus lisapunktideks, talletab KÕIK objektiga seotud atribuudid, meetodid jms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve(url,method='get',data=None,headers=None,auth=None):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML-ist ja HTML-ist otsimine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui lehe sisu on käes, tahame sellest eraldada huvipakkuva informatsiooni. XML-i ja HTML-i parsimiseks on palju erinevaid raamistikke. Püütonis on üheks väga heaks ja sageli kasutatavaks lahenduseks [_BeautifulSoup_](https://www.crummy.com/software/BeautifulSoup/), mis lisaks Püütonipärasele liidesele sisaldab hulka erinevaid parsereid ja tehnikaid. Teeki on võimalik kasutada nii suuremas süsteemis kui ka XML-i ja HTML-i dokumendiga tutvumiseks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content = requests.get('https://et.wikipedia.org/wiki/Kalevipoeg').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(content,'html.parser')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_BeautfifulSoup_ lubab otsida näiteks kõikide paragrahvide sisud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisaks on võimalik leida kindlate atribuutide väärtuste järgi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup.find(class_='firstHeading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup.find(id='siteSub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(soup.find(id='siteSub').text)\n",
    "print(soup.find(id='siteSub').attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iga positiivne otsingutulemus on juurega identse liidesega. See tähendab, et otsingu tulemustele saab rakendada alamotsinguid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup.find('html').body.div # first div in body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup.find_all('p')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup.find_all('p')[0].b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup.find_all('p')[0].find_all('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup.find_all('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 3.\n",
    "**Leidke _soup_ objekti läbi kõik Kalevipoja tekstis (paragrahvi märgendite vahel) olevad lingid. Järgnege linkide abil viidatud lehtedele ning leidke kõikide illustratiivsete piltide aadressid (võivad olla suhtelised). (1p)**\n",
    "\n",
    "Lahendamiseks tuleb leida soovitud suhtelised lingid, suhtelised lingid teisendada absoluutseteks, seejärel tõmmata alla absoluutsetelt aadressidelt sisu ning sisust otsida üles pildid.\n",
    "\n",
    "**NB:** kõik _img_ märgendid ei ole pildid - paljud sisaldavad kujundamisgraafikat (nt _svg_-d). Tuleb leida atribuudi, nime vms, mis pilte (joonistused, fotod jms) ühendab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boonusülesanne 2.\n",
    "\n",
    "**Visualiseerige programmaatiliselt üks juhuslik leitud pilt (kirjutage Püütoni kood, mis pilti _Notebook_'is kuvaks).  (0.5p)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 4.\n",
    "\n",
    "**Kirjutage funktsioonid, mis eraldaksid Postimehe _sitemap index_'ist _sitemap_'ide aadressid ning _sitemap_'ist vastavate artiklite aadressid. (1p)**\n",
    "\n",
    "Lahenduses võib kasutada näiteks _xml.etree_'d. Ehkki teoorias peaks ka _BeautifulSoup_'il olema _XML_'i parser, ei paista Püüton 3.5-s installimine triviaalne olevat.\n",
    "\n",
    "**NB: ** otsingutes peab _ElementTree_ korral nimeruumi ette panema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "url = 'http://www.postimees.ee/sitemap'\n",
    "\n",
    "def extract_sitemap_urls(sitemap_idx_url):\n",
    "    xml_root = ET.fromstring(requests.get(sitemap_idx_url).text)\n",
    "    print(xml_root)\n",
    "    # Finish me\n",
    "\n",
    "def extract_article_urls(sitemap_url):\n",
    "    # Finish me\n",
    "    pass\n",
    "\n",
    "extract_sitemaps(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl'imine\n",
    "\n",
    "![Roomamine](img/crawling.jpg)\n",
    "<center>https://www.yogatuneup.com/blog/2016/02/09/crawl-back-to-health/</center>\n",
    "\n",
    "Nüüdseks oleme juba salamahti tegelenud mitmete _crawl_'imise alamosadega. Me oleme tõmmanud üksikuid lehti, laiendanud ja külastanud _crawl frontier_'i, valinud URL-e, eraldanud olulisi dokumendiosi ning parsinud _sitemap_'e. Samas oleks palju veel teha.\n",
    "\n",
    "Praktikas on otstarbekas kasutada valmis raamistikke, mis hoolitsevad vaikimisi erinevate osade eest. Püütonis on kogunud populaarsust _scrape_'imise raamistik [_scrapy_](https://scrapy.org/).\n",
    "\n",
    "_Scrapy_'s on võimalik kasutada valmis kraapijaid või kirjutada enda omi, pärides raamistiku baasklasse. Raamistik võimaldab muuta lehelt informatsiooni eraldamisest URL-ide valimise ja tõmbamissageduseni. Lisaks saab _scrapy_ _crawler_'i panna jooksma [_scrapinghub_](https://scrapinghub.com) keskkonnas, kus tasuta paketi korral saab panna piiramatult kraapijaid, ühe kraapija kestus maksimaalset 24 tundi, maksimaalselt üks kraapija korraga ning andmeid hoitakse nädal aega. See tähendab, et ei pea enda arvutit öösiti jooksmas hoidma. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 5\n",
    "\n",
    "**Kirjutage _scrapy_ kraapija, mis otsiks Wiki folklooriga seotud lehtedelt potentsiaalseid tõelisi Eesti nimesid. Kommenteerige koodile juurde, kus asub teooriast tuttav _seed_, kus _visit_, kus laiendatakse _crawl frontier_'i ning kus näete 4 loengus mainitud _policy_'t töös. Kui kõiki ei leia (nt paralleelsus ei pruugi eksplitsiitselt esineda), pole hullu. (1.5p)**\n",
    "\n",
    "Nimeks võime pidada suure algustähega sõna, millele ei eelne lauselõpumärki. Mõned nimed on mitmesõnalised - selliseid võib pidada üheks nimeks.\n",
    "\n",
    "### Boonusülesanne 3.\n",
    "\n",
    "**Pange oma vastloodud kaunitar _scrapinghub_-i tunnikeseks jooksma mõistliku _politeness policy_'ga. Näiteks tõmmake iga 10 sekundi tagant. (0.5p)**\n",
    "\n",
    "<span style=\"color:red; font-weight:bold\">DDos rünnaku korral Wikile -3p.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sotsiaalmeedia\n",
    "\n",
    "Praktikumis tutvuge [_twitter_'i API-ga](https://dev.twitter.com/rest/public) ning [_Facebooki Graph API-ga_](https://developers.facebook.com/docs/graph-api).\n",
    "\n",
    "Ülesanded peagi tulekul..."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
